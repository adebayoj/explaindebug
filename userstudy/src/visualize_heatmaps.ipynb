{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500b698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.models import load_model\n",
    "import copy\n",
    "import PIL.Image\n",
    "# some plotting defaults\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid', {'axes.grid': False})\n",
    "SSIZE=10\n",
    "MSIZE=12\n",
    "BSIZE=14\n",
    "plt.rc('font', size=SSIZE)\n",
    "plt.rc('axes', titlesize=MSIZE)\n",
    "plt.rc('axes', labelsize=MSIZE)\n",
    "plt.rc('xtick', labelsize=MSIZE)\n",
    "plt.rc('ytick', labelsize=MSIZE)\n",
    "plt.rc('legend', fontsize=MSIZE)\n",
    "plt.rc('figure', titlesize=MSIZE)\n",
    "plt.rcParams['font.family'] = \"sans-serif\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67b17a",
   "metadata": {},
   "source": [
    "# Some Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path, resize=True,\n",
    "               sztple=(224, 224),\n",
    "               normalize=None):\n",
    "    \"\"\"Simple load image function.\"\"\"\n",
    "    img = PIL.Image.open(file_path).convert('RGB')\n",
    "    if resize:\n",
    "        img = img.resize(sztple, PIL.Image.ANTIALIAS)\n",
    "    img = np.asarray(img)\n",
    "    if normalize:\n",
    "        img = normalize(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def normalize_image(x):\n",
    "    \"\"\"Normalize the img.\"\"\"\n",
    "    x = np.array(x).astype(np.float32)\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    x_norm = (x - x_min) / (x_max - x_min)\n",
    "    return x_norm\n",
    "\n",
    "\n",
    "def grayscalenorm(img, percentile=99):\n",
    "    \"\"\"Normalize to [0, 1].\"\"\"\n",
    "    assert len(img.shape) == 3\n",
    "\n",
    "    img2d = np.sum(np.abs(img), axis=2)\n",
    "    vmax = np.percentile(img2d, percentile)\n",
    "    vmin = np.min(img2d)\n",
    "    return np.clip((img2d - vmin) / (vmax - vmin), 0, 1)\n",
    "\n",
    "\n",
    "def posnegnorm(img, percentile=99):\n",
    "    \"\"\"Normalize to [-1, 1].\"\"\"\n",
    "    assert len(img.shape) == 3\n",
    "\n",
    "    img2d = np.sum(img, axis=2)\n",
    "    span = abs(np.percentile(img2d, percentile))\n",
    "    vmax = span\n",
    "    vmin = -span\n",
    "    return np.clip((img2d - vmin) / (vmax - vmin), -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f528d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attributions(object):\n",
    "    \"\"\"Class for Attributions. Not efficient but for demo purposes.\"\"\"\n",
    "    def __init__(self, model, removetoplayer=True):\n",
    "        self.model = model\n",
    "        if removetoplayer: # need if model has softmax or some other layer after logits.\n",
    "            self.model.layers.pop()\n",
    "        self.logit_tensor = self.model.layers[-1].output[0] # get the logit tensor\n",
    "        self.input_tensor = [self.model.input]\n",
    "        self.grad = None\n",
    "        self.compute_gradients = None\n",
    "\n",
    "    def saliencymap(self, input_img, target_class):\n",
    "        self.grad = self.model.optimizer.get_gradients(\n",
    "            self.logit_tensor[target_class],\n",
    "            self.input_tensor)\n",
    "\n",
    "        self.compute_gradients = K.function(inputs=self.input_tensor,\n",
    "                                            outputs=self.grad)\n",
    "        saliency = self.compute_gradients([input_img])\n",
    "        return saliency[0]\n",
    "\n",
    "    def smoothgrad(self, input_img, target_class, noise_mean=0.0,\n",
    "                   noise_std_spread=0.15,\n",
    "                   nsamples=25):\n",
    "        maxinput = np.max(input_img)\n",
    "        mininput = np.min(input_img)\n",
    "        stdev = noise_std_spread * (maxinput - mininput)\n",
    "\n",
    "        total_gradients = np.zeros_like(input_img)\n",
    "        for i in range(nsamples):\n",
    "            noise = np.random.normal(0, stdev, input_img.shape)\n",
    "            input_plus_noise = input_img + noise\n",
    "            ingrad = self.saliencymap(input_plus_noise, target_class)\n",
    "            total_gradients += ingrad[0]\n",
    "\n",
    "        return total_gradients/nsamples\n",
    "\n",
    "    def integrated_gradients(self, input_img, target_class,\n",
    "                             baseline=None,\n",
    "                             xsteps=25):\n",
    "        if baseline is None:\n",
    "            baseline = np.zeros_like(input_img)\n",
    "\n",
    "        assert baseline.shape == input_img.shape\n",
    "\n",
    "        x_diff = input_img - baseline\n",
    "        total_gradients = np.zeros_like(input_img)\n",
    "        for alpha in np.linspace(0, 1, xsteps):\n",
    "            x_step = baseline + alpha * x_diff\n",
    "            ingrad = self.saliencymap(x_step, target_class)\n",
    "            total_gradients += ingrad[0]\n",
    "\n",
    "        return total_gradients * x_diff/xsteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17595faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Make sure to run the setup script and train models before running this cell.'''\n",
    "normal_model_path = '../models/epochs_40_lr_0.0001_batchsize_32_condition_normal_time_2021_07_29_12_16_39_AM_resnet50_best_freeze_weights.h5'\n",
    "normal_model = load_model(normal_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6fb817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process images and get predictions to prep for computing attributions\n",
    "sampleimgs = ['../data/testdogimgs/beagle_14.jpg',\n",
    "              '../data/testdogimgs/beagle_14_spurious.jpg']\n",
    "processed_imgs = []\n",
    "normal_model_prediction = []\n",
    "for path in sampleimgs:\n",
    "    img = load_image(path, resize=True, sztple=(224, 224))\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    processed_imgs.append(x)\n",
    "    preds_normal = normal_model.predict(x)\n",
    "    normal_model_prediction.append(preds_normal.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1653e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup attribution objects\n",
    "attrobject_normal = Attributions(normal_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute attributions for the two images for a normal model\n",
    "attributions_normal_collection = []\n",
    "attributions_spurious_collection = []\n",
    "for ind, x in enumerate(processed_imgs):\n",
    "    print(f\"On img: {ind}\")\n",
    "    indx = normal_model_prediction[ind]\n",
    "    \n",
    "    print(f\"Attributions for normal model.\")\n",
    "    sal = attrobject_normal.saliencymap(x, indx)\n",
    "    sm = attrobject_normal.smoothgrad(x, indx, nsamples=10)\n",
    "    ig = attrobject_normal.integrated_gradients(x, indx, xsteps=10)\n",
    "    attributions_normal_collection.append((sal, sm, ig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Beagle', 'Boxer', 'Chihuahua', 'Great Pyrenees',\n",
    "          'Newfoundlands', 'Pomeranian', 'Pugs', 'Saint Bernard',\n",
    "          'Wheaten Terrier', 'Yorkshire Terrier']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1363cb96",
   "metadata": {},
   "source": [
    "# Visualizing the attributions for a Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6fcf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect items to plot for img 1. Doing this manually for pedagogical reasons.\n",
    "img_1_prediction = normal_model_prediction[0]\n",
    "sal_img_1 = attributions_normal_collection[0][0]\n",
    "sm_img_1  = attributions_normal_collection[0][1]\n",
    "ig_img_1 = attributions_normal_collection[0][2]\n",
    "img_1 = load_image(sampleimgs[0], resize=True, sztple=(224, 224))\n",
    "\n",
    "img_2_prediction = normal_model_prediction[1]\n",
    "sal_img_2 = attributions_normal_collection[1][0]\n",
    "sm_img_2  = attributions_normal_collection[1][1]\n",
    "ig_img_2 = attributions_normal_collection[1][2]\n",
    "img_2 = load_image(sampleimgs[1], resize=True, sztple=(224, 224))\n",
    "\n",
    "fig, axs = plt.subplots(2, 4)\n",
    "axs[0][0].imshow(np.squeeze(img_1))\n",
    "axs[0][1].imshow(grayscalenorm(np.squeeze(sal_img_1)), cmap='gray')\n",
    "axs[0][2].imshow(grayscalenorm(np.squeeze(sm_img_1)), cmap = 'gray')\n",
    "axs[0][3].imshow(grayscalenorm(np.squeeze(ig_img_1)), cmap='gray')\n",
    "\n",
    "axs[1][0].imshow(np.squeeze(img_2))\n",
    "axs[1][1].imshow(grayscalenorm(np.squeeze(sal_img_2)), cmap='gray')\n",
    "axs[1][2].imshow(grayscalenorm(np.squeeze(sm_img_2)), cmap = 'gray')\n",
    "axs[1][3].imshow(grayscalenorm(np.squeeze(ig_img_2)), cmap='gray')\n",
    "# axs[4].imshow(newsalposnegnorm33, vmin=0.0, vmax=1.0, cmap='bwr')\n",
    "\n",
    "\n",
    "axs[0][0].set_title(\"Normal Input\\n\"+titles[img_1_prediction], fontsize=12, fontweight='bold',\n",
    "          color='red',\n",
    "          bbox={'facecolor': 'black',\n",
    "                'alpha': 0.8})\n",
    "axs[1][0].set_title(\"Spurious Input\\n\"+titles[img_2_prediction], fontsize=12, fontweight='bold',\n",
    "          color='red',\n",
    "          bbox={'facecolor': 'black',\n",
    "                'alpha': 0.8})\n",
    "axs[0][1].set_title(\"Model Attribution: Gradient\")\n",
    "axs[0][2].set_title(\"Model Attribution: SmoothGrad\")\n",
    "axs[0][3].set_title(\"Model Attribution: Integrated Gradients\")\n",
    "\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);  \n",
    "fig.set_figheight(9)\n",
    "fig.set_figwidth(18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
